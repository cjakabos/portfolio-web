services:
  jiraproxy:
    image: jiraproxy:latest
    container_name: jiraproxy
    build:
      context: ./
      dockerfile: Dockerfile_BE
      args:
        SERVICE_PATH: backend/web-proxy
    ports:
      - 8501:8501
    restart: unless-stopped
  vehicles-api:
    image: vehicles-api:latest
    container_name: vehicles-api
    build:
      context: ./
      dockerfile: Dockerfile_BE
      args:
        SERVICE_PATH: backend/vehicles-api
    ports:
      - 8880:8880
    restart: unless-stopped
  petstore:
    image: petstore:latest
    container_name: petstore
    build:
      context: ./
      dockerfile: Dockerfile_BE
      args:
        SERVICE_PATH: backend/petstore
    ports:
      - 8083:8083
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  cloudapp:
    image: cloudapp:latest
    container_name: cloudapp
    build:
      context: ./
      dockerfile: Dockerfile_BE
      args:
        SERVICE_PATH: backend/cloudapp
    ports:
      - 8099:8099
    environment:
      - DOCKER_HOST_IP=host.docker.internal
      - DOCKER_HOST_KAFKA_PORT=9092
    restart: unless-stopped
  mlops-segmentation:
    build:
      context: ./
      dockerfile: Dockerfile_PY
      args:
        SERVICE_PATH: backend/ml-pipeline
        SERVICE_PORT: 8600
    container_name: mlops-segmentation
    ports:
      - 8600:8600
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-nginx-jwt:
    container_name: next-nginx-jwt
    #    image: next-nginx-jwt:latest
    ports:
      - "80:80"
    build:
      context: ./frontend/nginx
      dockerfile: Dockerfile
    #    volumes:
    #      - ./frontend/nginx/conf/nginx.conf:/etc/nginx/nginx.conf
    #      - ./frontend/nginx/localhost+3-key.pub:/etc/nginx/localhost+3-key.pub
    depends_on:
      - cloudapp
      - petstore
      - jiraproxy
      - vehicles-api
      - mlops-segmentation
    restart: unless-stopped
  next-cloudapp-shell:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/cloudapp-shell
        SERVICE_PORT: 5001
        NEXT_PRIVATE_LOCAL_WEBPACK: true
    container_name: next-cloudapp-shell
    ports:
      - 5001:5001
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-openmaps:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/remote/openmaps
        SERVICE_PORT: 5002
        NEXT_PRIVATE_LOCAL_WEBPACK: true
    container_name: next-openmaps
    ports:
      - 5002:5002
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-jira:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/remote/jira
        SERVICE_PORT: 5003
        NEXT_PRIVATE_LOCAL_WEBPACK: true
        NEXT_PUBLIC_LLM_MODEL: 'deepseek-r1:1.5b'
        #NEXT_PUBLIC_JIRA_DOMAIN: 'https://your-jira-instance.atlassian.net'
        #NEXT_PUBLIC_JIRA_API_TOKEN: Y3NhYmFqYWthYm-------YOUR-API-KEY------SDA9REUzRjY4N0M=
        #NEXT_PUBLIC_JIRA_PROJECT_KEY: 'yourjiraprojectkey'
        #NEXT_PUBLIC_JIRA_EMAIL: 'youremail'
    container_name: next-jira
    ports:
      - 5003:5003
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-mlops:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/remote/mlops
        SERVICE_PORT: 5005
        NEXT_PRIVATE_LOCAL_WEBPACK: true
    container_name: next-mlops
    ports:
      - 5005:5005
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-petstore:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/remote/petstore
        SERVICE_PORT: 5006
        NEXT_PRIVATE_LOCAL_WEBPACK: true
    container_name: next-petstore
    ports:
      - 5006:5006
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped
  next-chatllm:
    build:
      context: ./
      dockerfile: Dockerfile_FE
      args:
        SERVICE_PATH: frontend/remote/chatllm
        SERVICE_PORT: 5333
        NEXT_PRIVATE_LOCAL_WEBPACK: true
        NEXT_PUBLIC_LLM_MODEL: 'deepseek-r1:1.5b'
    container_name: next-chatllm
    ports:
      - 5333:5333
    environment:
      - DOCKER_HOST_IP=host.docker.internal
    restart: unless-stopped