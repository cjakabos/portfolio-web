services:
  # ===========================================================================
  # DATABASE SERVICES - Internal only
  # ===========================================================================
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: websitemaster
      POSTGRES_PASSWORD: local
      POSTGRES_DB: cloudappdb
    ports:
      - "5433:5432"
    networks:
      - backend
    restart: unless-stopped

  postgres-ml:
    image: postgres:15
    volumes:
      - "./init-ml.sql:/docker-entrypoint-initdb.d/init-ml.sql"
    environment:
      POSTGRES_USER: segmentmaster
      POSTGRES_PASSWORD: segment
      POSTGRES_DB: segmentationdb
    ports:
      - "5434:5432"
    networks:
      - backend
    restart: unless-stopped

  mysql:
    image: mysql:8.0
    container_name: mysql-petstore
    ports:
      - "3307:3306"
    volumes:
      - petstore:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: petstore
    networks:
      - backend
    restart: unless-stopped

  mongo:
    image: mongo
    container_name: mongo-chat
    ports:
      - '27018:27017'
    environment:
      MONGO_INITDB_ROOT_USERNAME: websitemaster
      MONGO_INITDB_ROOT_PASSWORD: local
      MONGO_INITDB_DATABASE: cloudappdb
    networks:
      - backend
    restart: unless-stopped

  # ===========================================================================
  # MESSAGING SERVICES - Internal only
  # ===========================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.3
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - backend
    restart: unless-stopped

  broker:
    image: confluentinc/cp-kafka:7.2.3
    container_name: kafka
    ports:
      # To learn about configuring Kafka for access across networks see
      # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
      - "9093:9093"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_CREATE_TOPICS: 'chat'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9093,PLAINTEXT_HOST://host.docker.internal:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - backend
    restart: unless-stopped

# Local install on Apple Silicon to use GPU acceleration
# brew install ollama
# Get a few thinking AND tools model https://ollama.com/search?c=tools&c=thinking
# ollama pull qwen3:1.7b
# ollama pull deepseek-r1:1.5b
# Get an embedding model for RAG at ollama.com/search?c=embedding
# ollama pull qwen3-embedding:4b
# ollama serve
#  # ===========================================================================
#  # LLM Provider - Internal only
#  # ===========================================================================
#  ollama:
#    container_name: ollama
#    build:
#      context: ./
#      dockerfile: Dockerfile_OLLAMA
#      args:
#        NEXT_PUBLIC_LLM_MODEL: 'qwen3:1.7b'
#        NEXT_PUBLIC_LLM_MODEL_EMBEDDING: 'qwen3-embedding:4b'
#    restart: unless-stopped
#    ports:
#      - 11434:11434
#    networks:
#      - backend

  # ===========================================================================
  # AI ORCHESTRATION INFRASTRUCTURE - Internal only
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend

  mongodb-abtest:
    image: mongo:7
    container_name: mongodb-abtest
    restart: unless-stopped
    ports:
      - "27019:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin_password
      MONGO_INITDB_DATABASE: ai_orchestration
    volumes:
      - mongodb_data:/data/db
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend

  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb
    restart: unless-stopped
    ports:
      - "8123:8123"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8123/api/v1/heartbeat || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - backend

  # ===========================================================================
  # APPLICATION SERVICES
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # AI Orchestration Layer - Main API
  # ---------------------------------------------------------------------------
  ai-orchestration-layer:
    build:
      context: ./ai-orchestration/ai-orchestration-layer
      dockerfile: Dockerfile
      # Only keep build-time args that affect the image build itself
      args:
        PYTHONPATH: /app/src
        PYTHONUNBUFFERED: 1
    container_name: ai-orchestration-layer
    restart: unless-stopped
    # Runtime environment variables - these are read by os.getenv() in Python
    environment:
      # Python
      PYTHONPATH: /app/src
      PYTHONUNBUFFERED: 1

      # Environment
      ENVIRONMENT: ${ENVIRONMENT:-development}

      # LLM Configuration
      OLLAMA_URL: http://host.docker.internal:11434
      LLM_TEMPERATURE: ${LLM_TEMPERATURE:-0.7}
      LLM_MAX_TOKENS: ${LLM_MAX_TOKENS:-2000}

      # Service URLs (via NGINX gateway)
      CLOUDAPP_URL: ${CLOUDAPP_URL:-http://next-nginx-jwt:80/cloudapp}
      PETSTORE_URL: ${PETSTORE_URL:-http://next-nginx-jwt:80/petstore}
      VEHICLES_URL: ${VEHICLES_URL:-http://next-nginx-jwt:80/vehicles}
      ML_URL: ${ML_URL:-http://next-nginx-jwt:80/mlops-segmentation}
      POSTGRES_URL: postgresql://websitemaster:local@postgres:5432/cloudappdb

      # Redis Configuration
      REDIS_URL: redis://redis:6379/0
      REDIS_MAX_CONNECTIONS: ${REDIS_MAX_CONNECTIONS:-50}

      # MongoDB Configuration
      MONGODB_URL: mongodb://orchestration_user:orchestration_pass@mongodb-abtest:27017/ai_orchestration?authSource=ai_orchestration
      MONGODB_DATABASE: ai_orchestration

      # HTTP Client Configuration
      HTTP_TIMEOUT: ${HTTP_TIMEOUT:-10}
      HTTP_MAX_CONNECTIONS: ${HTTP_MAX_CONNECTIONS:-100}
      HTTP_MAX_KEEPALIVE: ${HTTP_MAX_KEEPALIVE:-20}

      # RAG Configuration
      CHROMA_HOST: chromadb
      CHROMA_PORT: 8123
      CHROMA_COLLECTION: ${CHROMA_COLLECTION:-user_documents}
      CHROMA_PERSIST_DIR: /data/chroma
      RAG_SEARCH_K: ${RAG_SEARCH_K:-3}

      # Feature Flags
      ENABLE_CHECKPOINTING: ${ENABLE_CHECKPOINTING:-true}
      ENABLE_HITL: ${ENABLE_HITL:-true}
      ENABLE_PARALLEL: ${ENABLE_PARALLEL:-true}
      ENABLE_ERROR_HANDLING: ${ENABLE_ERROR_HANDLING:-true}
      ENABLE_AB_TESTING: ${ENABLE_AB_TESTING:-true}

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    # NO ports exposed - only accessible via NGINX
    volumes:
      - chroma_data:/data/chroma
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_started
      chromadb:
        condition: service_started
#      ollama:
#        condition: service_started
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8700/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - backend

  # ===========================================================================
  # AI MONITOR DASHBOARD - Exposed to host (user-facing)
  # ===========================================================================
  ai-orchestration-monitor:
    build:
      context: ./ai-orchestration/ai-orchestration-monitor
      dockerfile: Dockerfile
      args:
        VITE_API_URL: http://localhost:80
        VITE_AI_BASE_URL: http://localhost:80/ai
        VITE_AI_WS_URL: ws://localhost:80/ai
        NODE_ENV: production
    container_name: ai-orchestration-monitor
    restart: unless-stopped
    ports:
      - "5010:5010"
    networks:
      - frontend

# ===========================================================================
# VOLUMES
# ===========================================================================
volumes:
  petstore:
  redis_data:
    name: ai-orchestration-redis
  mongodb_data:
    name: ai-orchestration-mongodb
  chroma_data:
    driver: local

# ===========================================================================
# NETWORKS - Must match docker-compose-app.yml
# ===========================================================================
networks:
  frontend:
    name: app-frontend
  backend:
    name: app-backend